next steps (week of 18.11.)
 x import stringdb (kind of done)
    ( requires ENSP -> ENSG mapping (or similarily))
    ( requires thus new id_mapping implementation)
 x look more closely at PSICQUIC (maybe i can load _all_ interactions without
     supplying all proteins)
   -> yep, easily, but parsing all of the results (differend ID types) might
      be a problem.
 x only use the sources that i don't yet have for interactions (i.e. exclude string)
 x check pdf document again (what needs to be added) and then send around
 - classify proteins into hk and ts and none-of-the-above
    - (use different classifications)
    - (design the software to be able to handle any classification,
       or somehow multiples in parallel (so the pipeline doesn't
       have to be re run every single time the classification is changed)
 - checkout algohub networkit repo, look at algorithm, look at how to
   extend the algorithm (this will be a butt-load of work right here)
   - extension for parallel analysis/ finding of functionally related clusters
     (graph clustering by co-expression score) and tissue specific/identifying
      clusters (graph clustering by co-expression and low-expression score)
 x send weekly report by wednesday (include the overview thesis pdf)
 x venn diagram analysis (ctd)
    (overlap expr <-> expr, ppi<->ppi (ids and edges), ppi<->expr coverage)
    x ppi<->expr coverage
    - ppi<->ppi (ids and edges + expected analysis)
    (including graphs and text!!)
 - start writing down the related work
       (data sources especially are easy to start with)
   and basics (properly cite everything, get a book for basics to cite/refer to)
 - think about reason for the MIN() thing in id_mapping

 x see alexis notes on the thesis structure
 - read gatto's paper
    - the clustering paper
    - and the tissue specific antibody paper
 x start with networkit stuff (see meyerhenke's email)

 x create node label (tissue specificity) output/export
  POSSIBILITIES:
   x create list of all possible tissues, outer join to each single protein
     (-> so that all are in the same exact order (even if some are missing)
     then either read out by single protein and combine expressed values
     programmatically via python or somehow use a custom GROUP BY operator
     that concatenates strings with a definable seperator
     somehow use a configurable value for NULL (no match in outer join)

NetworKit stuff:
----------------
    x only export (sub-)graph of PPI that is covered by expr
        x meaning a subgraph export function in ppi.py with list of proteins as
          parameter
    - use only those tissues and proteins so that everything is covered!?
        i.e. no NULL values
    - read in the edge list graph and the node labels
        x set up an outside project using the networKit (instead of modifying it)
        x io.EdgeList ?
        - read node labels into graph (sub)graph?
        - create subclass of graph or modify graph?
    - generate node degrees for all proteins in all tissues
        - think about how to import this back
        - maybe write an own graphio using SQLite?
        - sqlite from C++: https://github.com/SRombauts/SQLiteCpp
        - then import back into db??
        - why use files as exchange mechanism if I could use SQLite from C++
        - for both import and export of the graphs
    - write e-mail to meyerhenke regarding meeting
